{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization for Simplicity: Lâ‚‚ Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following **generalization curve**, which shows the loss for both the training set and validation set against the number of training iterations.\n",
    "\n",
    "![](img/11-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 shows a model in which training loss gradually decreases, but validation loss eventually goes up. In other words, this generalization curve shows that the model is [overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) to the data in the training set. Channeling our inner [Ockham](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting#ockham), perhaps we could prevent overfitting by penalizing complex models, a principle called regularization.\n",
    "\n",
    "In other words, instead of simply aiming to minimize loss (empirical risk minimization):\n",
    "\n",
    "$$minimize(Loss(Data|Model))$$\n",
    "\n",
    "We'll now minimize loss+complexity, which is called **structual risk minimization**: \n",
    "\n",
    "$$minimize(Loss(Data|Model) + complexity(Model))$$\n",
    "\n",
    "Our training optimization algorithm is now a function of two terms: the **loss term**, which measures how well the model fits the data, and the **regularization term**, which measures model complexity.\n",
    "\n",
    "Machine Learning Crash Course focuses on two common (and somewhat related) ways to think of model complexity:\n",
    "\n",
    "- Model complexity as a function of the weights of all the features in the model.\n",
    "- Model complexity as a function of the total number of features with nonzero weights. (A [later module](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization) covers this approach.)\n",
    "\n",
    "If model complexity is a function of weights, a feature weight with a high absolute value is more complex than a feature weight with a low absolute value.\n",
    "\n",
    "We can quantify complexity using the **L<sub>2</sub> regularization** formula, which defines the regularization term as the sum of the squares of all the feature weights:\n",
    "\n",
    "$$ L_2 regularization term = ||\\omega||^2_2 = \\omega^2_1 + \\omega^2_2 + ... + \\omega^2_n$$\n",
    "\n",
    "In this formula. weights close to zero have little effect on model complexity, while outlier weights can have a huge impact.\n",
    "\n",
    "For example, a linear model with the following weights:\n",
    "\n",
    "$${\\omega_1 = 0.2, \\omega_2 = 0.5, \\omega_3 = 5, \\omega_4 = 1, \\omega_5 = 0.25, \\omega_6 = 0.75}$$\n",
    "\n",
    "Has an L<sub>2</sub> regularization term of 26.915:\n",
    "\n",
    "$$ \\omega^2_1 + \\omega^2_2 + \\boldsymbol{\\omega^2_3} + \\omega^2_4 + \\omega^2_5 + \\omega^2_6$$\n",
    "$$ = 0.2^2 + 0.5^2 + \\boldsymbol{5^2} + 1^2 + 0.25^2 + 0.75^2$$\n",
    "%% = 0.44 + 0.25 + \\boldsymbol{25} + 1 + 0.0625 + 0.5625$$\n",
    "$$ = 26.915$$\n",
    "\n",
    "But $\\omega_3$ (bolded above), with a squared value of 25, contributes nearly all the complexity. The sum of the squares of all five other weights adds just 1.915 to the L<sub>2</sub> regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization for Simplicity: Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model developers tune the overall impact of the regularization term by multiplying its value by a scalar known as **lambda** (also called the **regularization rate**). That is, model developers aim to do the following:\n",
    "\n",
    "$$ minimize(Loss(Data|Model)) + \\lambda \\space complexity(Model)) $$\n",
    "\n",
    "Performing L<sub>2</sub> regularization has the following effect on a model\n",
    "\n",
    "- Encourages weight values toward 0 (but not exactly 0)\n",
    "- Encourages the mean of the weights toward 0, with a normal (bell-shaped or Gaussian) distribution.\n",
    "\n",
    "Increasing the lambda value strengthens the regularization effect. For example, the histogram of weights for a high value of lambda might look as shown in Figure 2.\n",
    "\n",
    "![](img/11-2.png)\n",
    "\n",
    "Lowering the value of lambda tends to yield a flatter histogram, as shown in Figure 3.\n",
    "\n",
    "![](img/11-3.png)\n",
    "\n",
    "When choosing a lambda value, the goal is to strike the right balance between simplicity and training-data fit:\n",
    "\n",
    "- If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data. Your model won't learn enough about the training data to make useful predictions.\n",
    "\n",
    "- If your lambda value is too low, your model will be more complex, and you run the risk of overfitting your data. Your model will learn too much about the particularities of the training data, and won't be able to generalize to new data.\n",
    "\n",
    "##### Note: Setting lambda to zero removes regularization completely. In this case, training focuses exclusively on minimizing loss, which poses the highest possible overfitting risk.\n",
    "\n",
    "The ideal value of lambda produces a model that generalizes well to new, previously unseen data. Unfortunately, that ideal value of lambda is data-dependent, so you'll need to do some tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a close connection between learning rate and lambda. Strong L2 regularization values tend to drive feature weights closer to 0. Lower learning rates (with early stopping) often produce the same effect because the steps away from 0 aren't as large. Consequently, tweaking learning rate and lambda simultaneously may have confounding effects.\n",
    "\n",
    "**Early stopping** means ending training before the model fully reaches convergence. In practice, we often end up with some amount of implicit early stopping when training in an [online](https://developers.google.com/machine-learning/crash-course/production-ml-systems) (continuous) fashion. That is, some new trends just haven't had enough data yet to converge.\n",
    "\n",
    "As noted, the effects from changes to regularization parameters can be confounded with the effects from changes in learning rate or number of iterations. One useful practice (when training across a fixed batch of data) is to give yourself a high enough number of iterations that early stopping doesn't play into things."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
